# Architecture Guide âš¡

A deep dive into MetalAudio's design â€” why things work the way they do, and how to get the most out of them.

> *"Understanding the amp before you crank it to 11."* ğŸ¸

*He was turned to steel in the great magnetic field â€” and so was this framework. Welcome, Iron Man.* ğŸ¤˜

## Overview

MetalAudio consists of three modules, each with a specific focus:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Your Application                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   MetalDSP              â”‚            MetalNN                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚            â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚   â€¢ FFT                 â”‚            â€¢ BNNSInference             â”‚
â”‚   â€¢ Convolution         â”‚            â€¢ Sequential                â”‚
â”‚   â€¢ Filters             â”‚            â€¢ Linear, Conv1D, LSTM...   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        MetalAudioKit                             â”‚
â”‚   â€¢ AudioDevice (GPU management)                                 â”‚
â”‚   â€¢ ComputeContext (triple buffering)                            â”‚
â”‚   â€¢ Tensor (GPU buffers)                                         â”‚
â”‚   â€¢ HardwareProfile (capability detection)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Apple Frameworks: Metal, Accelerate, BNNS, MPS          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MetalAudioKit â€” The Foundation

### AudioDevice

The GPU device manager. Think of it as your gear roadie â€” handles all the equipment setup so you can focus on playing.

**Key Features:**
- **Pipeline Caching**: LRU cache with max 64 entries. Shader compilation is expensive (~100-500ms), so we cache aggressively.
- **Thread Safety**: All public pipeline methods use double-checked locking. Safe to call from any thread after initialization.
- **Device Loss Handling**: Detects eGPU disconnection on macOS and gracefully degrades.

```swift
let device = try AudioDevice()

// Automatic GPU/CPU decision based on hardware and thermal state
if device.shouldUseGPU(forDataSize: bufferSize) {
    // Use GPU path
} else {
    // Fall back to Accelerate
}
```

### ComputeContext

Triple-buffered GPU execution designed for audio callbacks.

**Why Triple Buffering?**
- **Double buffering** can stall if GPU and CPU sync up badly
- **Triple buffering** ensures there's always a buffer available
- Uses `os_unfair_lock` â€” no priority inversion on audio thread

```swift
let context = try ComputeContext(device: device)

// Safe for audio callbacks â€” returns immediately if GPU busy
context.tryExecuteAsync(pipeline) { buffer in
    // Process...
}

// Block access via closures prevents TOCTOU races
context.withWriteBuffer { buffer in
    // Write to buffer...
}
```

### Tensor

Multi-dimensional GPU buffers with safety features.

**Validation:**
- Checks for NaN/Inf on copy operations
- Dimension validation on creation
- Alignment checks for Metal compatibility

### HardwareProfile

Detects device capabilities and adapts behavior.

**Monitored Factors:**
- GPU family and compute capabilities
- Thermal state (adjusts thresholds when hot)
- Low Power Mode (prefers CPU to save battery)
- Available memory

---

## MetalDSP â€” Signal Processing

### FFT

The crown jewel of MetalDSP â€” a hybrid implementation that picks the right tool for the job.

**Backend Selection:**

| Size | Backend | Why |
|------|---------|-----|
| â‰¤ 2048 | vDSP (Accelerate) | Lower latency, no GPU overhead |
| > 2048 | MPSGraph | GPU parallelism wins for large transforms |

*Threshold adjustable via `ToleranceConfiguration.gpuCpuThreshold`*

**STFT Support:**

```swift
let fft = try FFT(size: 4096, device: device)

// STFT with COLA validation
let stft = fft.stft(signal, hopSize: 1024, window: .hann)

// Check COLA compliance (important for reconstruction!)
let colaInfo = fft.config.validateCOLA()
if !colaInfo.isCompliant {
    print("Warning: \(colaInfo.message)")
}
```

**COLA-Compliant Hop Sizes:**
- **Hann**: size/2 (50%) or size/4 (75%)
- **Blackman**: size/3, size/4, or size/6
- **Hamming**: Near-COLA at 50%/75% (< 0.1% error)

**Thread Safety Note:**
`FFT` is NOT thread-safe for concurrent `forward()`/`inverse()` calls. Create separate instances per thread. Exception: `forwardBatch()` IS thread-safe (uses internal thread-local buffers).

### Convolution

Three modes, each optimized for different scenarios:

| Mode | Best For | Notes |
|------|----------|-------|
| **Direct** | Short kernels (< 16K samples) | Default. Uses vDSP cross-correlation. |
| **FFT** | Long kernels (â‰¥ 16K, â‰¥ 50% of input) | One-shot processing. True convolution. |
| **Partitioned** | Real-time streaming with long impulses | Perfect for reverb IRs. |

**Partitioned Convolution:**
- Maintains internal ring buffer state
- Call `reset()` between unrelated audio streams
- `useMPSGraphFFT: true` is faster for large blocks but has first-call JIT latency

### Filters

**BiquadFilter:**
- NOT thread-safe â€” use one instance per channel
- Two processing modes:
  - `process(input:)` â€” vDSP batch, best for complete buffers
  - `process(sample:)` â€” direct equation, best for real-time/modulation
- Validates pole stability on parameter changes

---

## MetalNN â€” Neural Audio

### BNNSInference (macOS 15+ / iOS 18+)

Zero-allocation inference wrapper for Apple's BNNS Graph. This is the key to running neural networks in audio callbacks.

> *"The quiet workhorse â€” no allocations, no drama."*

**Critical Settings:**
```swift
let inference = try BNNSInference(
    modelPath: modelURL,
    singleThreaded: true  // REQUIRED for audio thread!
)
```

**Why `singleThreaded: true`?**
- Audio threads have real-time priority
- Multi-threaded BNNS can spawn worker threads
- Worker threads = priority inversion = glitches

**Memory Pressure Handling:**
```swift
inference.memoryPressureDelegate = self

func bnnsInference(_ inference: BNNSInference,
                   didReceiveMemoryPressure level: MemoryPressureLevel) -> Bool {
    // Return false to keep workspace (for audio, usually the right choice)
    return false
}
```

### Layer Execution Strategies

**Linear Layer:**
| Batch Size | Backend | Why |
|------------|---------|-----|
| < 4 | Accelerate BLAS | `cblas_sgemv`/`cblas_sgemm` faster for small batches |
| â‰¥ 4 | MPS GPU | GPU parallelism wins |

*Threshold configurable via `Linear.mpsBatchThreshold`*

**LSTM/GRU:**
- **CPU-only by design** â€” sequential dependencies make naive GPU slower than Accelerate
- Uses AMX coprocessor on Apple Silicon via Accelerate BLAS
- For GPU LSTM: use `BNNSInference` with a compiled Core ML model (~12x faster than custom Metal!)
- Pre-warm with `lstm.prewarm(sequenceLength:)` to avoid runtime allocations

**Conv1D:**
Three shader variants, selected automatically:
- `conv1d_forward` â€” Basic kernel for small operations
- `conv1d_forward_tiled` â€” Cooperative loading for kernel > 16 samples
- `conv1d_forward_vec4` â€” Vectorized for moderate kernels with large outputs

### Sequential Model

Model container with intelligent buffer management.

**Ping-Pong Buffer Optimization:**
```swift
let model = Sequential()
model.add(conv1)
model.add(conv2)
model.add(conv3)
model.build()  // Analyzes shapes, enables buffer reuse

print(model.bufferStats)
// "10 layers, 2 buffers (80% reduction)"
```

Layers with compatible output shapes share buffers in an alternating pattern. A 10-layer network with identical shapes uses only 2 buffers instead of 10.

### HybridPipeline

For encoder-LSTM-decoder architectures (common in audio ML):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Encoder   â”‚ â”€â”€â–¶ â”‚  Bottleneck  â”‚ â”€â”€â–¶ â”‚   Decoder   â”‚
â”‚   (Conv1D)  â”‚     â”‚    (LSTM)    â”‚     â”‚(ConvTrans1D)â”‚
â”‚  Metal GPU  â”‚     â”‚  BNNS CPU    â”‚     â”‚  Metal GPU  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Each stage uses its optimal backend
- Zero-copy on Apple Silicon unified memory
- Falls back gracefully if BNNS unavailable

---

## HTDemucs â€” Music Source Separation

> *"Splitting the mix like a prism splits light â€” six stems of pure audio clarity."* ğŸ¸

HTDemucs (Hybrid Transformer Demucs) is a state-of-the-art neural network for music source separation, separating mixed audio into 6 stems: drums, bass, other, vocals, guitar, and piano.

### Architecture Overview

```text
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚         Input Audio             â”‚
                        â”‚      [2, samples] stereo        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                         â”‚                         â”‚
              â–¼                         â”‚                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Time Encoder   â”‚                 â”‚               â”‚   STFT          â”‚
    â”‚  (1D U-Net)     â”‚                 â”‚               â”‚  [nfft=4096]    â”‚
    â”‚                 â”‚                 â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  Conv1D + GN    â”‚                 â”‚                        â”‚
    â”‚  Ã—5 levels      â”‚                 â”‚                        â–¼
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                          â”‚               â”‚  Freq Encoder   â”‚
             â”‚ skip connections         â”‚               â”‚  (2D U-Net)     â”‚
             â”‚                          â”‚               â”‚                 â”‚
             â–¼                          â”‚               â”‚  Conv2D + GN    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚               â”‚  Ã—5 levels      â”‚
    â”‚ Time Bottleneck â”‚                 â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚   [768, T/256]  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                          â”‚               â”‚ Freq Bottleneck â”‚
             â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   [768, F, T']  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Cross-Transformer       â”‚â—„â”€â”€â”˜
                        â”‚   (5 layers)              â”‚
                        â”‚                           â”‚
                        â”‚  â€¢ Self-attention (time)  â”‚
                        â”‚  â€¢ Cross-attention (tâ†”f)  â”‚
                        â”‚  â€¢ Self-attention (freq)  â”‚
                        â”‚  â€¢ FFN                    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚                         â”‚
              â–¼                     â”‚                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Time Decoder   â”‚             â”‚               â”‚  Freq Decoder   â”‚
    â”‚  (1D U-Net)     â”‚             â”‚               â”‚  (2D U-Net)     â”‚
    â”‚                 â”‚             â”‚               â”‚                 â”‚
    â”‚  ConvT1D + GN   â”‚             â”‚               â”‚  ConvT2D + GN   â”‚
    â”‚  + skip concat  â”‚             â”‚               â”‚  + skip concat  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚                        â”‚
             â–¼                      â”‚                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Output Heads   â”‚             â”‚               â”‚   iSTFT         â”‚
    â”‚  (Ã—6 stems)     â”‚             â”‚               â”‚  + Output Heads â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚                        â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚         6 Stem Outputs          â”‚
                        â”‚  drums, bass, other, vocals,    â”‚
                        â”‚  guitar, piano                  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Inference Modes

| Mode | Speed | Quality | Use Case |
|------|-------|---------|----------|
| `.timeOnly` | Fast (~3x) | ~70% | Real-time preview, streaming |
| `.full` | Slow | 100% | Final render, offline processing |

**Time-only mode** processes only the time-domain path, skipping STFT, frequency U-Net, and cross-transformer. Useful for real-time previews.

**Full mode** processes both paths with cross-transformer fusion, providing maximum quality at the cost of latency.

### Configuration

```swift
// Default configuration for htdemucs_6s
let config = HTDemucs.Config.htdemucs6s
// - encoderChannels: [48, 96, 192, 384, 768]
// - kernelSize: 8, stride: 4
// - numGroups: 8 (for GroupNorm)
// - nfft: 4096, hopLength: 1024
// - crossAttentionLayers: 5, heads: 8, dim: 512
```

---

## Attention Mechanisms

### Scaled Dot-Product Attention

The core attention operation used throughout HTDemucs and transformer layers:

```text
Attention(Q, K, V) = softmax(QÂ·K^T / âˆšd_k) Â· V
```

**Numerical Stability:**

- Uses max-subtract trick in softmax: `softmax(x) = softmax(x - max(x))`
- Prevents overflow for large attention scores
- Handles variable-length sequences with masking

### Multi-Head Attention

```swift
let attention = try MultiHeadAttention(
    device: device,
    embedDim: 512,
    numHeads: 8,
    dropoutRate: 0.0  // No dropout for inference
)
```

**Weight Layout (PyTorch compatible):**

- `in_proj_weight`: [3 * embedDim, embedDim] â€” packed Q, K, V projections
- `in_proj_bias`: [3 * embedDim]
- `out_proj.weight`: [embedDim, embedDim]
- `out_proj.bias`: [embedDim]

---

## U-Net Architecture

U-Net is an encoder-decoder architecture with skip connections, essential for preserving fine details in audio reconstruction.

### 1D U-Net (Time Domain)

```text
Input [C, L]
    â”‚
    â”œâ”€â”€â–º[Encoder 0]â”€â”€â–º[48, L/4]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚                                 â”‚
    â”‚                     â”œâ”€â”€â–º[Encoder 1]â”€â”€â–º[96, L/16]â”€â”€â”€â”€â”€â”â”‚
    â”‚                     â”‚                     â”‚          â”‚â”‚
    â”‚                     â”‚                     ...        â”‚â”‚
    â”‚                     â”‚                     â”‚          â”‚â”‚
    â”‚                     â”‚                   [768, L/1024]â†â”˜â”‚
    â”‚                     â”‚                     â”‚          â”‚â”‚
    â”‚                     â”‚                     â–¼          â”‚â”‚
    â”‚                     â”‚              [Decoder 4]â”€â”€â”€â”€â”€â”€â–ºâ”‚â”‚
    â”‚                     â”‚                     â”‚          â”‚â”‚
    â”‚                     â”‚                     ...        â”‚â”‚
    â”‚                     â”‚                     â”‚          â”‚â”‚
    â”‚                     â””â”€â”€â–º[Decoder 1]â—„â”€â”€â”€â”€â”€â”˜          â”‚
    â”‚                              â”‚                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º[Decoder 0]â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        Output [C, L]
```

**Skip Connection Strategy:**

- Each encoder level stores output for corresponding decoder level
- Decoder concatenates upsampled input with skip connection
- `SkipConnectionPool` manages storage by level index

### 2D U-Net (Frequency Domain)

Same architecture but operates on spectrograms `[C, F, T]`:

- Uses 2D convolutions with 3Ã—3 kernels
- Stride (2, 2) for downsampling
- Reflect padding for edge handling
- `SkipConnectionPool2D` for 3D tensors

---

## GroupNorm Algorithm Variants

GroupNorm divides channels into groups and normalizes within each group. HTDemucs uses 8 groups throughout.

### Algorithm Selection

| Algorithm | Accuracy | Speed | Use Case |
|-----------|----------|-------|----------|
| `.standard` | ~5e-4 | Fastest | Production, when speed matters |
| `.kahan` | ~2e-4 | ~1.1x | Balanced accuracy/speed |
| `.welford` | ~5e-5 | ~1.2x | Maximum accuracy, validation |

```swift
let groupNorm = try GroupNorm(device: device, numGroups: 8, numChannels: 48)
try groupNorm.setAlgorithm(.welford)  // Maximum accuracy
```

**Note:** GPU driver variability can cause NaN issues on some systems. The Welford algorithm is more numerically stable and recommended for production.

---

## Thread Safety Summary

| Component | Thread-Safe? | Notes |
|-----------|--------------|-------|
| `AudioDevice` | âœ… Yes | After initialization |
| `ComputeContext` | âœ… Yes | Uses `os_unfair_lock` |
| `Tensor` | âš ï¸ Partially | Safe for reads, not concurrent writes |
| `FFT` | âŒ No | Create per-thread instances |
| `FFT.forwardBatch()` | âœ… Yes | Uses thread-local buffers |
| `BiquadFilter` | âŒ No | One instance per channel |
| `BNNSInference` | âœ… Yes | With `singleThreaded: true` |

---

## Real-Time Audio Checklist

Before shipping to production, verify:

- [ ] All buffers pre-allocated during `init` or `allocateRenderResources()`
- [ ] No Swift Array/Dictionary operations in render callback
- [ ] Using `tryExecuteAsync` (non-blocking) instead of `executeAsync`
- [ ] `BNNSInference` created with `singleThreaded: true`
- [ ] No file I/O, network, or other blocking calls
- [ ] Tested under memory pressure (Instruments â†’ Memory Pressure)
- [ ] Profiled with Instruments â†’ Time Profiler for audio thread

---

*Now go forth and make your audio callbacks sing. You're on the Highway to Hell (45Î¼s latency edition).* ğŸ¤˜âš¡
